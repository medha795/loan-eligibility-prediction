{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5cabd3db-f45c-4a61-b38f-ed2d7e5ddb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path \n",
    "from typing import List \n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "#--Paths-- \n",
    "INPUT_PATH = Path(\"C:/Users/Medha/Projects/loan-eligibility-prediction/data/processed/combined_loan_data_processed.csv\") \n",
    "OUTPUT_PATH = Path(\"C:/Users/Medha/Projects/loan-eligibility-prediction/data/processed/engineered_loan_dataset.csv\") \n",
    "\n",
    "#--Column Definitions--\n",
    "RAW_CATEGORICAL_COLUMNS = [\n",
    "    \"term\", \n",
    "    \"emp_length\", \n",
    "    \"home_ownership\", \n",
    "    \"purpose\", \n",
    "    \"addr_state\", \n",
    "    \"application_type\", \n",
    "] \n",
    "\n",
    "RAW_NUMERIC_COLUMNS = [\n",
    "    \"loan_amnt\", \n",
    "    \"int_rate\", \n",
    "    \"annual_inc\", \n",
    "    \"dti\", \n",
    "    \"delinq_2yrs\", \n",
    "    \"fico_range_high\", \n",
    "    \"fico_range_low\", \n",
    "    \"inq_last_6mths\", \n",
    "] \n",
    "\n",
    "TARGET_COLUMN = \"loan_status\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7632453-70e1-4ad3-90c0-4b93ac819872",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parse_term(term_value : str) -> float: \n",
    "    \"\"\"Convert terms like '36 months' to the numeric month count.\"\"\"\n",
    "    if pd.isna(term_value): \n",
    "        return np.nan\n",
    "    digits = \"\".join(ch for ch in str(term_value) if ch.isdigit())\n",
    "    return float(digits) if digits else np.nan\n",
    "\n",
    "def _parse_emp_length(emp_length_value : str) -> float: \n",
    "    \"\"\"Normalize employment length strings to a numeric year count.\"\"\"\n",
    "    if pd.isna(emp_length_value):\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "    value = str(emp_length_value).strip().lower()\n",
    "    if value in {\"10+ years\", \"10 years\", \"10+\"}: \n",
    "        return 10.0\n",
    "    if value in {\"< 1 year\", \"<1 year\", \"<1\"}:\n",
    "        return 0.0\n",
    "    digits = \"\".join(ch for ch in value if ch.isdigit())\n",
    "    return float(digits) if digits else np.nan\n",
    "\n",
    "\n",
    "def _parse_percentage(value : str) -> float: \n",
    "    \"\"\"Strip percent signs and cast to float.\"\"\"\n",
    "    if pd.isna(value): \n",
    "        return np.nan\n",
    "    cleaned = str(value).replace(\"%\", \"\").strip()\n",
    "    return float(cleaned) if cleaned else np.nan \n",
    "\n",
    "\n",
    "def _build_fico_score(df: pd.DataFrame) -> pd.Series: \n",
    "    \"\"\"Combine high/low ranges into a single representative score.\"\"\"\n",
    "    low = df.get(\"fico_range_low\") \n",
    "    high = df.get(\"fico_range_high\") \n",
    "\n",
    "\n",
    "    #Prefer the midpoint when both are present, otherwise fall back \n",
    "    if low is not None and high is not None: \n",
    "        return (pd.to_numeric(low, errors = \"coerce\") + \n",
    "                pd.to_numeric(high, errors = \"coerce\")) / 2\n",
    "    if low is not None: \n",
    "        return pd.to_numeric(low, errors = \"coerce\") \n",
    "    if high is not None: \n",
    "        return pd.to_numeric(high, errors = \"coerce\") \n",
    "    return pd.Series(np.nan, index = df.index)\n",
    "\n",
    "def _normalize_columns(df: pd.DataFrame) -> pd.DataFrame: \n",
    "    \"\"\"Lowercase and strip column names for consistency.\"\"\"\n",
    "    normalized = df.copy()\n",
    "    normalized.columns = normalized.columns.str.lower().str.strip()\n",
    "    return normalized \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21b6f559-4acd-42b2-82c5-2fa9d7b4a504",
   "metadata": {},
   "outputs": [],
   "source": [
    "def engineer_features(df: pd.DataFrame) -> pd.DataFrame: \n",
    "\n",
    "    \"\"\"\n",
    "    Return a cleaned, model-ready dataframe. \n",
    "\n",
    "    Steps \n",
    "    ------------\n",
    "    * Standardize column casing \n",
    "    * Parse text percentages and term/tenure fields to numerics \n",
    "    * Build a single fico_score \n",
    "    * Impute missing values with medians (numeric) and most-common labels (categorical) \n",
    "    * One-hot encode categorical features \n",
    "    * Convert the target label to a binary indicator (1 = accepted, 0 = rejected) \n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    #Normalize columns \n",
    "    df = _normalize_columns(df) \n",
    "    working = df.copy()\n",
    "\n",
    "    #----- Parse engineered numeric features -----\n",
    "    if \"term\" in working: \n",
    "        working[\"term_months\"] = working[\"term\"].apply(_parse_term)\n",
    "\n",
    "    if \"emp_length\" in working: \n",
    "        working[\"emp_length_years\"] = working[\"emp_length\"].apply(_parse_emp_length)\n",
    "        \n",
    "    if \"int_rate\" in working: \n",
    "        working[\"int_rate\"] = working[\"int_rate\"].apply(_parse_percentage)\n",
    "\n",
    "    if \"dti\" in working: \n",
    "        working[\"dti\"] = working[\"dti\"].apply(_parse_percentage) \n",
    "\n",
    "    working[\"fico_score\"] = _build_fico_score(working) \n",
    "\n",
    "    # ----- Target label encoding -----\n",
    "    if TARGET_COLUMN in working: \n",
    "        working[TARGET_COLUMN] = (\n",
    "            working[TARGET_COLUMN] \n",
    "            .astype(str)\n",
    "            .str.strip()\n",
    "            .str.lower()\n",
    "            .map({\"accepted\" :1, \"rejected\" : 0})\n",
    "        )\n",
    "        #Keep only rows with valid mapped labels (0 or 1) \n",
    "        mask_valid = working[TARGET_COLUMN].isin([0,1])\n",
    "        working = working[mask_valid].copy()\n",
    "\n",
    "    # ----- Identify numeric and categorical features -----\n",
    "    numeric_features : List[str] = []\n",
    "    for column in RAW_NUMERIC_COLUMNS + [\"term_months\", \"emp_length_years\", \"fico_score\"]: \n",
    "        if column in working.columns: \n",
    "            numeric_features.append(column) \n",
    "            working[column] = pd.to_numeric(working[column], errors = \"coerce\") \n",
    "\n",
    "    categorical_features: List[str] = []\n",
    "    for column in RAW_CATEGORICAL_COLUMNS: \n",
    "        if column in working.columns: \n",
    "            categorical_features.append(column) \n",
    "            working[column] = working[column].astype(str).str.strip().str.lower()\n",
    "\n",
    "    # ----- Impute missing values ----- \n",
    "    if numeric_features: \n",
    "        for column in numeric_features: \n",
    "            working[column] = working[column].fillna(working[column].median())\n",
    "\n",
    "    if caterogical_features: \n",
    "        for column in categorical_features: \n",
    "            working[column] = working[column].replace({\"nan\":np.nan})\n",
    "            mode = working[column].mode(dropna= True)\n",
    "            fill_value = mode.iloc[0] if not mode.empty else \"unknown\"\n",
    "            working[column] = working[column].fillna(fill_value)\n",
    "\n",
    "    # ----- One-hot encode categoricals -----\n",
    "    if categorical_features: \n",
    "        encoded = pd.get_dummies(\n",
    "            working[categorical_features], \n",
    "            prefix = categorical_features, \n",
    "            drop_first = False\n",
    "        )\n",
    "    else: \n",
    "        encoded = pd.DataFrame(index = working.index) \n",
    "\n",
    "    # ----- Assemble final dataframe -----\n",
    "    feature_part = pd.concat(\n",
    "        [working[numeric_features], encoded], \n",
    "        axis = 1\n",
    "    ) \n",
    "\n",
    "    if TARGET_COLUMN in working.columns: \n",
    "        feature_part[TARGET_COLUMN] = working[TARGET_COLUMN].astype(int)\n",
    "\n",
    "\n",
    "    return feature_part\n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07c1d2e1-3489-45df-9591-5ae62ce1f51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def engineer_and_save(input_path: Path, output_path: Path) -> pd.DataFrame:\n",
    "    \"\"\"Load the combined dataset, engineer features, save, and return the df.\"\"\"\n",
    "    if not input_path.exists():\n",
    "        raise FileNotFoundError(f\"Input file not found at: {input_path}\")\n",
    "\n",
    "    print(f\"Loading input dataset from: {input_path}\")\n",
    "    df_raw = pd.read_csv(input_path, low_memory = False)\n",
    "    print(f\"  Raw Shape: {df_raw.shape}\")\n",
    "\n",
    "    df_engineered = engineer_features(df_raw)\n",
    "    print(f\"Engineered shape: {df_engineered.shape}\") \n",
    "\n",
    "    output_path.parent.mkdir(parents = True, exist_ok = True)\n",
    "    df_engineered.to_csv(output_path, index = False) \n",
    "    print(f\"Saved engineered dataset to: {output_path}\")\n",
    "\n",
    "    return df_engineered "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11f3b78e-73fd-4d48-97a1-abb64eb30720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading input dataset from: C:\\Users\\Medha\\Projects\\loan-eligibility-prediction\\data\\processed\\combined_loan_data_processed.csv\n",
      "  Raw Shape: (29909442, 15)\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 456. MiB for an array with shape (29909442,) and data type complex128",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Run the full engineering pipeline and inspect results \u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m engineered_df \u001b[38;5;241m=\u001b[39m \u001b[43mengineer_and_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43mINPUT_PATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mOUTPUT_PATH\u001b[49m\u001b[43m)\u001b[49m \n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mPreview of engineered dataset:\u001b[39m\u001b[38;5;124m\"\u001b[39m) \n\u001b[0;32m      6\u001b[0m display(engineered_df\u001b[38;5;241m.\u001b[39mhead())\n",
      "Cell \u001b[1;32mIn[4], line 10\u001b[0m, in \u001b[0;36mengineer_and_save\u001b[1;34m(input_path, output_path)\u001b[0m\n\u001b[0;32m      7\u001b[0m df_raw \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(input_path, low_memory \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  Raw Shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf_raw\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 10\u001b[0m df_engineered \u001b[38;5;241m=\u001b[39m \u001b[43mengineer_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_raw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngineered shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf_engineered\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \n\u001b[0;32m     13\u001b[0m output_path\u001b[38;5;241m.\u001b[39mparent\u001b[38;5;241m.\u001b[39mmkdir(parents \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, exist_ok \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[3], line 60\u001b[0m, in \u001b[0;36mengineer_features\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m column \u001b[38;5;129;01min\u001b[39;00m working\u001b[38;5;241m.\u001b[39mcolumns: \n\u001b[0;32m     59\u001b[0m         categorical_features\u001b[38;5;241m.\u001b[39mappend(column) \n\u001b[1;32m---> 60\u001b[0m         working[column] \u001b[38;5;241m=\u001b[39m \u001b[43mworking\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcolumn\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrip\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;66;03m# ----- Impute missing values ----- \u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m numeric_features: \n",
      "File \u001b[1;32m~\\miniconda3\\envs\\loan_eligibility\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:140\u001b[0m, in \u001b[0;36mforbid_nonstring_types.<locals>._forbid_nonstring_types.<locals>.wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    135\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    136\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot use .str.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with values of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    137\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minferred dtype \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_dtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    138\u001b[0m     )\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m--> 140\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\loan_eligibility\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:3222\u001b[0m, in \u001b[0;36mStringMethods.lower\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   3219\u001b[0m \u001b[38;5;129m@Appender\u001b[39m(_shared_docs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcasemethods\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m%\u001b[39m _doc_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlower\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m   3220\u001b[0m \u001b[38;5;129m@forbid_nonstring_types\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbytes\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m   3221\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mlower\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m-> 3222\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_str_lower\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3223\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_result(result)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\loan_eligibility\\lib\\site-packages\\pandas\\core\\strings\\object_array.py:481\u001b[0m, in \u001b[0;36mObjectStringArrayMixin._str_lower\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    480\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_str_lower\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 481\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_str_map\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\loan_eligibility\\lib\\site-packages\\pandas\\core\\strings\\object_array.py:82\u001b[0m, in \u001b[0;36mObjectStringArrayMixin._str_map\u001b[1;34m(self, f, na_value, dtype, convert)\u001b[0m\n\u001b[0;32m     80\u001b[0m map_convert \u001b[38;5;241m=\u001b[39m convert \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39mall(mask)\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 82\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer_mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muint8\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_convert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mAttributeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;66;03m# Reraise the exception if callable `f` got wrong number of args.\u001b[39;00m\n\u001b[0;32m     85\u001b[0m     \u001b[38;5;66;03m# The user may want to be warned by this, instead of getting NaN\u001b[39;00m\n\u001b[0;32m     86\u001b[0m     p_err \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     87\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m((takes)|(missing)) (?(2)from \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md+ to )?\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md+ \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     88\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(?(3)required )positional arguments?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     89\u001b[0m     )\n",
      "File \u001b[1;32mpandas/_libs/lib.pyx:2930\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer_mask\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas/_libs/lib.pyx:2556\u001b[0m, in \u001b[0;36mpandas._libs.lib.maybe_convert_objects\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 456. MiB for an array with shape (29909442,) and data type complex128"
     ]
    }
   ],
   "source": [
    "# Run the full engineering pipeline and inspect results \n",
    "\n",
    "engineered_df = engineer_and_save(INPUT_PATH, OUTPUT_PATH) \n",
    "\n",
    "print(\"\\nPreview of engineered dataset:\") \n",
    "display(engineered_df.head())\n",
    "\n",
    "print(\"\\nInfo:\")\n",
    "print(engineered_df.info())\n",
    "\n",
    "if TARGET_COLUMN in engineered_df.columns: \n",
    "    print(\"\\nTarget distribution:\") \n",
    "    print(engineered_df[TARGET_COLUMN].value_counts(dropna=False))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8e1476-350c-46c1-bedd-8401893b000e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Loan Eligibility Env",
   "language": "python",
   "name": "loan_eligibility"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
